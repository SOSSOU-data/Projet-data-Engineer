# Ecommerce Analytics - Projet ETL

![Python](https://img.shields.io/badge/Python-3.12-blue)
![Pandas](https://img.shields.io/badge/Pandas-1.6.2-lightgrey)
![Google API](https://img.shields.io/badge/Google-API-green)

## ğŸ“Œ Contexte

Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre de la formation **Data Engineering**. L'objectif est de mettre en place un **pipeline ETL complet** pour collecter, transformer et charger des donnÃ©es e-commerce provenant de Google Drive, puis les prÃ©parer pour analyse.

Le pipeline prend en charge :
- Les donnÃ©es clients (plusieurs fichiers CSV).
- Les donnÃ©es produits (fichier CSV unique).

## ğŸ“ Structure du projet

```
ecommerce-analytics/
â”‚
â”œâ”€ data/
â”‚  â”œâ”€ raw_data/
â”‚  â”‚  â”œâ”€ clients/          # Fichiers clients tÃ©lÃ©chargÃ©s depuis Google Drive
â”‚  â”‚  â””â”€ products/         # Fichier produits tÃ©lÃ©chargÃ© depuis Google Drive
â”‚  â”œâ”€ processed/           # Fichiers transformÃ©s (nettoyÃ©s et concatÃ©nÃ©s)
â”‚  â””â”€ load/                # Fichiers finaux prÃªts pour utilisation ou analyse
â”‚
â”œâ”€ src/
â”‚  â”œâ”€ dags/
â”‚  â”‚  â””â”€ common/
â”‚  â”‚     â”œâ”€ extract.py     # Extraction depuis Google Drive
â”‚  â”‚     â”œâ”€ transform.py   # Transformation et nettoyage des fichiers
â”‚  â”‚     â””â”€ load.py        # Chargement des fichiers transformÃ©s
â”‚  â””â”€ config.py            # Configuration des chemins et Service Account
â”‚
â”œâ”€ main.py                 # Script principal pour lancer l'ETL complet
â””â”€ README.md
```

## âš™ï¸ Fonctionnement du pipeline ETL

Le pipeline comprend trois Ã©tapes : **Extraction, Transformation et Chargement**.

### 1. Extraction (extract.py)
- RÃ©cupÃ¨re les fichiers clients et produits depuis Google Drive.
- TÃ©lÃ©charge les fichiers dans `data/raw_data/clients` et `data/raw_data/products`.
- Gestion des erreurs pour fichiers non trouvÃ©s ou inaccessibles.

### 2. Transformation (transform.py)
- Clients : concatÃ©nation de tous les CSV, suppression des doublons, vÃ©rification des fichiers vides.
- Produits : lecture du fichier unique, suppression des doublons et gestion des erreurs.
- Sauvegarde des fichiers transformÃ©s dans `data/processed/`.

### 3. Chargement (load.py)
- DÃ©place les fichiers transformÃ©s vers `data/load/` pour utilisation ou analyse.
- Fichiers finaux :
  - `clients_final.csv`
  - `products_final.csv`

## ğŸ› ï¸ PrÃ©requis

- Python 3.10 ou supÃ©rieur
- BibliothÃ¨ques :
```bash
pip install pandas google-api-python-client google-auth google-auth-httplib2 google-auth-oauthlib
```
- Service Account Google Drive configurÃ© avec accÃ¨s aux fichiers CSV.

## ğŸš€ Instructions pour exÃ©cuter le projet

1. **Cloner le dÃ©pÃ´t**
```bash
git clone <URL_DE_TON_REPO>
cd ecommerce-analytics
```

2. **CrÃ©er les dossiers nÃ©cessaires**
```bash
mkdir -p data/raw_data/clients data/raw_data/products data/processed data/load
```

3. **Supprimer les fichiers compilÃ©s Python (optionnel)**
```bash
find . -type f -name "*.pyc" -delete
find . -type d -name "__pycache__" -exec rm -r {} +
```

4. **Exporter le PYTHONPATH**
```bash
export PYTHONPATH=$(pwd)/src
```

5. **Lancer le pipeline ETL complet**
```bash
python main.py
```

6. **VÃ©rifier les fichiers finaux**
- `data/load/clients_final.csv`
- `data/load/products_final.csv`

## âš ï¸ Gestion des erreurs

- Fichiers clients vides ou invalides : warning et ignorÃ©s.
- Fichiers produits vides ou invalides : erreur affichÃ©e.
- Les logs dÃ©taillent chaque Ã©tape pour faciliter le debug.

## ğŸ’¡ Auteur

**Alpha Lansar**
Formation Data Engineering
Projet rÃ©alisÃ© dans le cadre du TP `ecommerce-analytics`.

