# Ecommerce Analytics - Pipeline ETL

![Python](https://img.shields.io/badge/Python-3.12-blue)
![Pandas](https://img.shields.io/badge/Pandas-1.6.2-lightgrey)
![Google API](https://img.shields.io/badge/Google-API-green)

## ğŸ“Œ Table des matiÃ¨res

* [Contexte](#-contexte)
* [Structure du projet](#-structure-du-projet)
* [Fonctionnement du pipeline](#-fonctionnement-du-pipeline)
* [PrÃ©requis](#-prÃ©requis)
* [Installation et lancement](#-installation-et-lancement)
* [Gestion des erreurs](#-gestion-des-erreurs)
* [Technologies utilisÃ©es](#-technologies-utilisÃ©es)
* [Licence](#-licence)
* [Auteur](#-auteur)

## ğŸ“Œ Contexte

Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre de la formation **Data Engineering de DATA Afrique HUB**.
Il implÃ©mente un **pipeline ETL complet** pour collecter, transformer et charger des donnÃ©es e-commerce depuis Google Drive afin de les prÃ©parer pour analyse.

Le pipeline gÃ¨re :

* Les donnÃ©es clients (plusieurs fichiers CSV).
* Les donnÃ©es produits (fichier CSV unique).

##ğŸ“ Structure du projet

```
ecommerce-analytics/
â”‚
â”œâ”€ data/
â”‚  â”œâ”€ raw_data/          # DonnÃ©es brutes tÃ©lÃ©chargÃ©es depuis Google Drive
â”‚  â”‚  â”œâ”€ clients/
â”‚  â”‚  â””â”€ products/
â”‚  â”œâ”€ processed/         # DonnÃ©es nettoyÃ©es et transformÃ©es
â”‚  â””â”€ load/              # Fichiers finaux prÃªts pour analyse
â”‚
â”œâ”€ src/
â”‚  â”œâ”€ dags/
â”‚  â”‚  â””â”€ common/
â”‚  â”‚     â”œâ”€ extract.py    # Extraction depuis Google Drive
â”‚  â”‚     â”œâ”€ transform.py  # Nettoyage et transformation
â”‚  â”‚     â””â”€ load.py       # Chargement final des fichiers
â”‚  â””â”€ config.py           # Configuration des chemins et paramÃ¨tres
â”‚
â”œâ”€ main.py                # Script principal pour exÃ©cuter le pipeline ETL
â””â”€ README.md
```

## âš™ï¸ Fonctionnement du pipeline

Le pipeline ETL suit trois Ã©tapes principales :

### 1. Extraction (`extract.py`)

* TÃ©lÃ©chargement des fichiers clients et produits depuis Google Drive.
* Stockage dans `data/raw_data/clients` et `data/raw_data/products`.
* Gestion des erreurs pour fichiers manquants ou inaccessibles.

### 2. Transformation (`transform.py`)

* Clients : concatÃ©nation, suppression des doublons et vÃ©rification des fichiers vides.
* Produits : nettoyage et gestion des doublons.
* Sauvegarde des fichiers transformÃ©s dans `data/processed/`.

### 3. Chargement (`load.py`)

* DÃ©placement des fichiers transformÃ©s vers `data/load/`.
* Fichiers finaux gÃ©nÃ©rÃ©s :

  * `clients_final.csv`
  * `products_final.csv`

## ğŸ› ï¸ PrÃ©requis

* Python 3.10 ou supÃ©rieur
* BibliothÃ¨ques Python :

```bash
pip install pandas google-api-python-client google-auth google-auth-httplib2 google-auth-oauthlib
```

* Compte Service Account Google Drive configurÃ© avec accÃ¨s aux fichiers CSV.

## ğŸš€ Installation et lancement

1. Cloner le dÃ©pÃ´t :

```bash
git clone https://github.com/AlphaLansar/ecommerce-analytics.git
cd ecommerce-analytics
```

2. CrÃ©er les dossiers de donnÃ©es :

```bash
mkdir -p data/raw_data/clients data/raw_data/products data/processed data/load
```

3. Exporter le PYTHONPATH :

```bash
export PYTHONPATH=$(pwd)/src
```

4. ExÃ©cuter le pipeline ETL complet :

```bash
python main.py
```

5. VÃ©rifier les fichiers finaux :

* `data/load/clients_final.csv`
* `data/load/products_final.csv`

## âš ï¸ Gestion des erreurs

* Fichiers clients vides : warning, ignorÃ©s.
* Fichiers produits vides ou invalides : erreur affichÃ©e.
* Les logs dÃ©taillent chaque Ã©tape pour faciliter le debug.

## ğŸ–¥ï¸ Technologies utilisÃ©es

* Python 3.12
* Pandas 1.6.2
* Google API (Drive, OAuth2)
* Git & GitHub

## ğŸ“„ Licence

Ce projet n'est pas sous licence.
## ğŸ’¡ Auteur

**Alpha Abdoulaye Lansar**
Formation Data Engineering â€“ Projet TP `ecommerce-analytics`
